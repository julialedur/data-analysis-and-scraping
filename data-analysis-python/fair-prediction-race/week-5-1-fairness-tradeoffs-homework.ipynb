{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 5-2: Fair prediction\n",
    "\n",
    "In this homework you will experiment with modifying the logistic regression classifier we built on the COMPAS data, tuning it to get equal false positive rates between black and white defendants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0. Loading the data and building the feature matrix.\n",
    "Free code, copied from our class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select between data on overall arrests and arrests for violent crimes\n",
    "# This allows quick comparisons of the difference between these two data sets\n",
    "violent = False\n",
    "\n",
    "if violent:\n",
    "    fname ='compas-scores-two-years-violent.csv'\n",
    "    decile_col = 'v_decile_score'\n",
    "    score_col = 'v_score_text'\n",
    "else:\n",
    "    fname ='compas-scores-two-years.csv'\n",
    "    decile_col = 'decile_score'\n",
    "    score_col = 'score_text'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 53)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning ala ProPublica\n",
    "cv = cv[\n",
    "    (cv.days_b_screening_arrest <= 30) &  \n",
    "    (cv.days_b_screening_arrest >= -30) &  \n",
    "    (cv.is_recid != -1) &\n",
    "    (cv.c_charge_degree != 'O') &\n",
    "    (cv[score_col] != 'N/A')\n",
    "]\n",
    "\n",
    "# Keep only black and white races for this analysis\n",
    "cv = cv[(cv.race == 'African-American') | (cv.race=='Caucasian')]\n",
    "         \n",
    "# renumber the rows from 0 again\n",
    "cv.reset_index(inplace=True, drop=True) \n",
    "cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up dummy variables for age, race, gender\n",
    "features = pd.concat(\n",
    "    [pd.get_dummies(cv.age_cat, prefix='age'),\n",
    "     pd.get_dummies(cv.sex, prefix='sex'),\n",
    "     pd.get_dummies(cv.c_charge_degree, prefix='degree'), # felony or misdemeanor charge ('f' or 'm')\n",
    "     cv.priors_count],\n",
    "    axis=1)\n",
    "\n",
    "# We should have one less dummy variable than the number of categories, to avoid the \"dummy variable trap\"\n",
    "# See https://www.quora.com/When-do-I-fall-in-the-dummy-variable-trap\n",
    "features.drop(['age_25 - 45', 'sex_Female', 'degree_M'], axis=1, inplace=True)\n",
    "\n",
    "# Try to predict whether someone is re-arrested\n",
    "target = cv.two_year_recid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Your basic logistic regression\n",
    "\n",
    "Fit a logistic regression to this data. Print out the accuracy, PPV, and FPV overall, and for just black vs. white defendants. \n",
    "\n",
    "Most of the code you need can be found in the class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression\n",
    "\n",
    "x = features.values\n",
    "y = target.values\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the result on the training data\n",
    "\n",
    "y_pred = lr.predict(x)\n",
    "guessed=pd.Series(y_pred)==1\n",
    "actual=cv.two_year_recid==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free code for you!\n",
    "\n",
    "# cm is a confusion matrix. The rows are guessed, the columns are actual \n",
    "def print_ppv_fpv(cm):\n",
    "    # the indices here are [col][row] or [actual][guessed]\n",
    "    TN = cm[False][False]   \n",
    "    TP = cm[True][True]\n",
    "    FN = cm[True][False]\n",
    "    FP = cm[False][True]\n",
    "    print('Accuracy: ', (TN+TP)/(TN+TP+FN+FP))\n",
    "    print('PPV: ', TP / (TP + FP))\n",
    "    print('FPR: ', FP / (FP + TN))\n",
    "    print('FNR: ', FN / (FN + TP))\n",
    "    print()\n",
    "\n",
    "def print_metrics(guessed, actual):\n",
    "    cm = pd.crosstab(guessed, actual, rownames=['guessed'], colnames=['actual'])\n",
    "    print(cm)\n",
    "    print()\n",
    "    print_ppv_fpv(cm)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     2076   1047\n",
      "True       719   1436\n",
      "\n",
      "Accuracy:  0.665403561955286\n",
      "PPV:  0.6663573085846868\n",
      "FPR:  0.25724508050089445\n",
      "FNR:  0.4216673378977044\n",
      "\n",
      "White\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1061    493\n",
      "True       220    329\n",
      "\n",
      "Accuracy:  0.6609605325725154\n",
      "PPV:  0.599271402550091\n",
      "FPR:  0.1717408274785324\n",
      "FNR:  0.5997566909975669\n",
      "\n",
      "Black\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1015    554\n",
      "True       499   1107\n",
      "\n",
      "Accuracy:  0.6683464566929134\n",
      "PPV:  0.6892901618929016\n",
      "FPR:  0.3295904887714663\n",
      "FNR:  0.33353401565322094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy, PPV, FPV, FNV for\n",
    "#  - everyone \n",
    "#  - just white defendants\n",
    "#  - just black defendants\n",
    "\n",
    "\n",
    "print('Everyone')\n",
    "print_metrics(guessed, actual)\n",
    "\n",
    "print('White')\n",
    "subset = cv.race == 'Caucasian'\n",
    "print_metrics(guessed[subset], actual[subset])\n",
    "\n",
    "print('Black')\n",
    "subset = cv.race == 'African-American'\n",
    "print_metrics(guessed[subset], actual[subset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Equalizing false positive rates\n",
    "Now you'll build your own classifier that equalizes the false positive rates between white and non-white defendants. There are many ways to do this. We're going to use race explicitly to set a different threshold for white and black defendants. \n",
    "\n",
    "To begin with, we are going to write our own prediction function, starting with this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a trained LogisticRegression, a set of features, and a threshold\n",
    "# Predicts true wherever the regression gives a probability > threshold\n",
    "# Note: returns a numpy array, not a dataframe\n",
    "def predict_threshold(classifier, features, threshold):\n",
    "    # predict_proba returns two columns: probability of true, and probability of false\n",
    "    # [:,1] selects the second column\n",
    "    return classifier.predict_proba(features)[:,1] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as lr.predict(x) when we use a threshold of 0.5\n",
    "guessed2 = predict_threshold(lr, x, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adapt this function so it takes two thresholds `a_threshold` and `b_threshold`, and a column of values `use_b` which means use the `b_threshold` for any row where it's true. The idea is to allow us to adjust the thresholds independently on two different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function which takes the following arguments\n",
    "def predict_threshold_groups(classifier, feautes, a_threshold, b_threshold, use_b):\n",
    "    # calculate probabilities from our classifier\n",
    "    \n",
    "    probabilities = classifier.predict_proba(features)[:,1]\n",
    "    \n",
    "    # Create one Series which is True where the probabilities are bigger than a_threshold, \n",
    "    # and another for b_threshold\n",
    "    # Then combine them, selecting values from either Series according to use_b\n",
    "    guess = pd.Series(probabilities > a_threshold)\n",
    "    guess.loc[use_b] = pd.Series(probabilities > b_threshold)\n",
    "    return guess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this function with different thresholds for black and white defendants. Print out the confusion martrix, accuracy, FPV, and PPV for the results -- again, overall and for each race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     2305   1360\n",
      "True       490   1123\n",
      "\n",
      "Accuracy:  0.6494884425918909\n",
      "PPV:  0.6962182269063856\n",
      "FPR:  0.17531305903398928\n",
      "FNR:  0.5477245267821184\n",
      "\n",
      "White\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1061    493\n",
      "True       220    329\n",
      "\n",
      "Accuracy:  0.6609605325725154\n",
      "PPV:  0.599271402550091\n",
      "FPR:  0.1717408274785324\n",
      "FNR:  0.5997566909975669\n",
      "\n",
      "Black\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1244    867\n",
      "True       270    794\n",
      "\n",
      "Accuracy:  0.6418897637795276\n",
      "PPV:  0.7462406015037594\n",
      "FPR:  0.178335535006605\n",
      "FNR:  0.5219747140276941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict recidivism with different thresholds for black and white\n",
    "# Print out metrics for everyone, black, and white\n",
    "\n",
    "guessed2 = predict_threshold_groups(lr, x, 0.5, 0.585, cv.race=='African-American')\n",
    "\n",
    "print('Everyone')\n",
    "print_metrics(guessed2, actual)\n",
    "\n",
    "print('White')\n",
    "subset = cv.race == 'Caucasian'\n",
    "print_metrics(guessed2[subset], actual[subset])\n",
    "\n",
    "print('Black')\n",
    "subset = cv.race == 'African-American'\n",
    "print_metrics(guessed2[subset], actual[subset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the thresholds so the False Positive Rate is the same for white and black defendants.\n",
    "- What did you change to achive this?\n",
    "- What effect does this have on the overall accuracy, FPR, FNR, and PPV?\n",
    "- What effect does this have on the PPV for white and black?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case I raised the threshold for black defendants from 0.5 to 0.585, which equalizes the FPR at about 17%. The overall accuracy fell only slightly from 66% to 65%, and the accuracy for black defendants fell from 67% to 64%. But the PPV for black defendants -- the probability that someone who is categorized as high risk will actually be re-arrested within two years -- increased from 69% to 75%, because the higher threshold removes some of the people who were not particularly risky from the high risk group. The cost is a higher false negative rate for black defendents, which has gone up from 33% to 52%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Predicting race and the impossibility of blinding\n",
    "So far we've excluded race as a predictive variable, hoping that this would make the results unbiased. But is race encoded in the other data points? To find out, alter the regression above to try to predict race from the other demographic and criminal history variables.\n",
    "\n",
    "How accurately can you predict race just on these factors alone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65151515, 0.64204545, 0.64109848, 0.63033175, 0.64549763])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cross validation and the classifier of your choice to see how well you can predict race\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x = features.values\n",
    "y = cv.race.values\n",
    "my_classifier = tree.DecisionTreeClassifier()\n",
    "scores = cross_val_score(my_classifier, x, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this accuracy to just guessing one race all the time. Which race is more common in this data and what would the accuracy be if we just always guessed that race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3175\n",
       "Caucasian           2103\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most common race in our arrest data?\n",
    "cv.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015536187949981"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the accuracy if we always guess the most common race?\n",
    "3175 / (3175+2103)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, how much information about race \"leaks\" into our original recidivism predictor, even if we don't give it the race variable as a feature?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
